{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "K5kUuzRlQyHM"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.datasets import load_digits\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "from tinymlgen import port"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "a95JYma8Q4r7"
   },
   "outputs": [],
   "source": [
    "def get_data():\n",
    "    np.random.seed(1337)\n",
    "    x_values, y_values = load_digits(return_X_y=True)\n",
    "    x_values /= x_values.max()\n",
    "    # reshape to (8 x 8 x 1)\n",
    "    x_values = x_values.reshape((len(x_values), 8, 8, 1))\n",
    "\n",
    "    # split into train, validation, test\n",
    "    TRAIN_SPLIT = int(0.6 * len(x_values))\n",
    "    TEST_SPLIT = int(0.2 * len(x_values) + TRAIN_SPLIT)\n",
    "    x_train, x_test, x_validate = np.split(x_values, [TRAIN_SPLIT, TEST_SPLIT])\n",
    "    y_train, y_test, y_validate = np.split(y_values, [TRAIN_SPLIT, TEST_SPLIT])\n",
    "\n",
    "    return x_train, x_test, x_validate, y_train, y_test, y_validate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "0jxKJriLQ6e4"
   },
   "outputs": [],
   "source": [
    "def get_model():\n",
    "    x_train, x_test, x_validate, y_train, y_test, y_validate = get_data()\n",
    "\n",
    "    # create a CNN\n",
    "    model = tf.keras.Sequential()\n",
    "    model.add(layers.Conv2D(8, (3, 3), activation='relu', input_shape=(8, 8, 1)))\n",
    "    # model.add(layers.MaxPooling2D((2, 2)))\n",
    "    model.add(layers.Flatten())\n",
    "    model.add(layers.Dense(len(np.unique(y_train))))\n",
    "\n",
    "    model.compile(optimizer='adam', loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True), metrics=['accuracy'])\n",
    "    model.fit(x_train, y_train, epochs=50, batch_size=16,\n",
    "                        validation_data=(x_validate, y_validate))\n",
    "    return model, x_test, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "RhCESc9sQ761"
   },
   "outputs": [],
   "source": [
    "def test_model(model, x_test, y_test):\n",
    "    x_test = (x_test / x_test.max()).reshape((len(x_test), 8, 8, 1))\n",
    "    y_pred = model.predict(x_test).argmax(axis=1)\n",
    "\n",
    "    print('ACCURACY', (y_pred == y_test).sum() / len(y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "tb9pledSQ79Z",
    "outputId": "170904a1-19b2-4395-8176-7bb3e71336ff",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\BatuhanYILMAZ\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\convolutional\\base_conv.py:99: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m68/68\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.3082 - loss: 2.1792 - val_accuracy: 0.7333 - val_loss: 1.6376\n",
      "Epoch 2/50\n",
      "\u001b[1m68/68\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8490 - loss: 1.3862 - val_accuracy: 0.8444 - val_loss: 0.9010\n",
      "Epoch 3/50\n",
      "\u001b[1m68/68\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9330 - loss: 0.6590 - val_accuracy: 0.8417 - val_loss: 0.6212\n",
      "Epoch 4/50\n",
      "\u001b[1m68/68\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9407 - loss: 0.4142 - val_accuracy: 0.8583 - val_loss: 0.5175\n",
      "Epoch 5/50\n",
      "\u001b[1m68/68\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9368 - loss: 0.2775 - val_accuracy: 0.8500 - val_loss: 0.4776\n",
      "Epoch 6/50\n",
      "\u001b[1m68/68\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9531 - loss: 0.2159 - val_accuracy: 0.8611 - val_loss: 0.4646\n",
      "Epoch 7/50\n",
      "\u001b[1m68/68\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9569 - loss: 0.1915 - val_accuracy: 0.8583 - val_loss: 0.4424\n",
      "Epoch 8/50\n",
      "\u001b[1m68/68\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9690 - loss: 0.1598 - val_accuracy: 0.8667 - val_loss: 0.4244\n",
      "Epoch 9/50\n",
      "\u001b[1m68/68\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9618 - loss: 0.1497 - val_accuracy: 0.8528 - val_loss: 0.4374\n",
      "Epoch 10/50\n",
      "\u001b[1m68/68\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9678 - loss: 0.1334 - val_accuracy: 0.8639 - val_loss: 0.4251\n",
      "Epoch 11/50\n",
      "\u001b[1m68/68\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9705 - loss: 0.1124 - val_accuracy: 0.8639 - val_loss: 0.4223\n",
      "Epoch 12/50\n",
      "\u001b[1m68/68\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9747 - loss: 0.1007 - val_accuracy: 0.8667 - val_loss: 0.4142\n",
      "Epoch 13/50\n",
      "\u001b[1m68/68\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9674 - loss: 0.1185 - val_accuracy: 0.8722 - val_loss: 0.4065\n",
      "Epoch 14/50\n",
      "\u001b[1m68/68\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9781 - loss: 0.0868 - val_accuracy: 0.8750 - val_loss: 0.4171\n",
      "Epoch 15/50\n",
      "\u001b[1m68/68\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9803 - loss: 0.0886 - val_accuracy: 0.8750 - val_loss: 0.4047\n",
      "Epoch 16/50\n",
      "\u001b[1m68/68\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9804 - loss: 0.0791 - val_accuracy: 0.8861 - val_loss: 0.4102\n",
      "Epoch 17/50\n",
      "\u001b[1m68/68\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9854 - loss: 0.0695 - val_accuracy: 0.8778 - val_loss: 0.3966\n",
      "Epoch 18/50\n",
      "\u001b[1m68/68\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9759 - loss: 0.0768 - val_accuracy: 0.8889 - val_loss: 0.3972\n",
      "Epoch 19/50\n",
      "\u001b[1m68/68\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9870 - loss: 0.0702 - val_accuracy: 0.8917 - val_loss: 0.4121\n",
      "Epoch 20/50\n",
      "\u001b[1m68/68\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9926 - loss: 0.0579 - val_accuracy: 0.8972 - val_loss: 0.4105\n",
      "Epoch 21/50\n",
      "\u001b[1m68/68\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9856 - loss: 0.0639 - val_accuracy: 0.8889 - val_loss: 0.4252\n",
      "Epoch 22/50\n",
      "\u001b[1m68/68\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9841 - loss: 0.0621 - val_accuracy: 0.8833 - val_loss: 0.4465\n",
      "Epoch 23/50\n",
      "\u001b[1m68/68\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9831 - loss: 0.0639 - val_accuracy: 0.8917 - val_loss: 0.3907\n",
      "Epoch 24/50\n",
      "\u001b[1m68/68\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9898 - loss: 0.0511 - val_accuracy: 0.8889 - val_loss: 0.4155\n",
      "Epoch 25/50\n",
      "\u001b[1m68/68\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9915 - loss: 0.0492 - val_accuracy: 0.8861 - val_loss: 0.4468\n",
      "Epoch 26/50\n",
      "\u001b[1m68/68\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9926 - loss: 0.0413 - val_accuracy: 0.8972 - val_loss: 0.4252\n",
      "Epoch 27/50\n",
      "\u001b[1m68/68\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9958 - loss: 0.0378 - val_accuracy: 0.8861 - val_loss: 0.4321\n",
      "Epoch 28/50\n",
      "\u001b[1m68/68\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9926 - loss: 0.0406 - val_accuracy: 0.8917 - val_loss: 0.4497\n",
      "Epoch 29/50\n",
      "\u001b[1m68/68\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9904 - loss: 0.0408 - val_accuracy: 0.8944 - val_loss: 0.4101\n",
      "Epoch 30/50\n",
      "\u001b[1m68/68\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9945 - loss: 0.0371 - val_accuracy: 0.9000 - val_loss: 0.4457\n",
      "Epoch 31/50\n",
      "\u001b[1m68/68\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9961 - loss: 0.0353 - val_accuracy: 0.9000 - val_loss: 0.4357\n",
      "Epoch 32/50\n",
      "\u001b[1m68/68\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9942 - loss: 0.0310 - val_accuracy: 0.8944 - val_loss: 0.4406\n",
      "Epoch 33/50\n",
      "\u001b[1m68/68\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9943 - loss: 0.0352 - val_accuracy: 0.8917 - val_loss: 0.4269\n",
      "Epoch 34/50\n",
      "\u001b[1m68/68\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9943 - loss: 0.0320 - val_accuracy: 0.9000 - val_loss: 0.4259\n",
      "Epoch 35/50\n",
      "\u001b[1m68/68\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9964 - loss: 0.0330 - val_accuracy: 0.9000 - val_loss: 0.4540\n",
      "Epoch 36/50\n",
      "\u001b[1m68/68\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9982 - loss: 0.0296 - val_accuracy: 0.9028 - val_loss: 0.4382\n",
      "Epoch 37/50\n",
      "\u001b[1m68/68\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9942 - loss: 0.0309 - val_accuracy: 0.8972 - val_loss: 0.4645\n",
      "Epoch 38/50\n",
      "\u001b[1m68/68\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9970 - loss: 0.0326 - val_accuracy: 0.8944 - val_loss: 0.4916\n",
      "Epoch 39/50\n",
      "\u001b[1m68/68\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9982 - loss: 0.0254 - val_accuracy: 0.8972 - val_loss: 0.4542\n",
      "Epoch 40/50\n",
      "\u001b[1m68/68\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9991 - loss: 0.0232 - val_accuracy: 0.8972 - val_loss: 0.4585\n",
      "Epoch 41/50\n",
      "\u001b[1m68/68\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9978 - loss: 0.0229 - val_accuracy: 0.8972 - val_loss: 0.4845\n",
      "Epoch 42/50\n",
      "\u001b[1m68/68\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9989 - loss: 0.0236 - val_accuracy: 0.9028 - val_loss: 0.4650\n",
      "Epoch 43/50\n",
      "\u001b[1m68/68\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9997 - loss: 0.0201 - val_accuracy: 0.8972 - val_loss: 0.4834\n",
      "Epoch 44/50\n",
      "\u001b[1m68/68\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9936 - loss: 0.0240 - val_accuracy: 0.9000 - val_loss: 0.4977\n",
      "Epoch 45/50\n",
      "\u001b[1m68/68\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9974 - loss: 0.0189 - val_accuracy: 0.9028 - val_loss: 0.4771\n",
      "Epoch 46/50\n",
      "\u001b[1m68/68\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9972 - loss: 0.0206 - val_accuracy: 0.8972 - val_loss: 0.4800\n",
      "Epoch 47/50\n",
      "\u001b[1m68/68\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9980 - loss: 0.0152 - val_accuracy: 0.8972 - val_loss: 0.4978\n",
      "Epoch 48/50\n",
      "\u001b[1m68/68\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0146 - val_accuracy: 0.9000 - val_loss: 0.4971\n",
      "Epoch 49/50\n",
      "\u001b[1m68/68\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9996 - loss: 0.0167 - val_accuracy: 0.8972 - val_loss: 0.5017\n",
      "Epoch 50/50\n",
      "\u001b[1m68/68\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9998 - loss: 0.0134 - val_accuracy: 0.8972 - val_loss: 0.4938\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step \n",
      "ACCURACY 0.9554317548746518\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    model, x_test, y_test = get_model()\n",
    "    test_model(model, x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('my_model.keras')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "LRkXQ2HOUivq",
    "outputId": "5b75f83f-5ddb-40bd-f9d3-ecf4b477db39"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mkdir: cannot create directory ‘output’: File exists\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "13820"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# convert and save the model in TFLite format\n",
    "\n",
    "!mkdir output\n",
    "converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
    "tflite_model = converter.convert()\n",
    "open(\"output/cnn_mnist_model.tflite\", \"wb\").write(tflite_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "id": "V60TIpDNJTGj"
   },
   "outputs": [],
   "source": [
    "!xxd -i output/cnn_mnist_model.tflite > output/cnn_mnist_model.h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "pym08Vb2OB6q",
    "outputId": "abd96309-5133-4be3-c017-6aee5bf9a46e",
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "// Digit 0\n",
      "float x_test[64] = {\n",
      "0.000000f, 0.000000f, 0.312500f, 0.812500f, 0.562500f, 0.062500f, 0.000000f, 0.000000f, \n",
      "0.000000f, 0.000000f, 0.812500f, 0.937500f, 0.625000f, 0.937500f, 0.312500f, 0.000000f, \n",
      "0.000000f, 0.187500f, 0.937500f, 0.125000f, 0.000000f, 0.687500f, 0.500000f, 0.000000f, \n",
      "0.000000f, 0.250000f, 0.750000f, 0.000000f, 0.000000f, 0.500000f, 0.500000f, 0.000000f, \n",
      "0.000000f, 0.312500f, 0.500000f, 0.000000f, 0.000000f, 0.562500f, 0.500000f, 0.000000f, \n",
      "0.000000f, 0.250000f, 0.687500f, 0.000000f, 0.062500f, 0.750000f, 0.437500f, 0.000000f, \n",
      "0.000000f, 0.125000f, 0.875000f, 0.312500f, 0.625000f, 0.750000f, 0.000000f, 0.000000f, \n",
      "0.000000f, 0.000000f, 0.375000f, 0.812500f, 0.625000f, 0.000000f, 0.000000f, 0.000000f, \n",
      "};\n",
      "\n",
      "// Digit 1\n",
      "float x_test[64] = {\n",
      "0.000000f, 0.000000f, 0.000000f, 0.750000f, 0.812500f, 0.312500f, 0.000000f, 0.000000f, \n",
      "0.000000f, 0.000000f, 0.000000f, 0.687500f, 1.000000f, 0.562500f, 0.000000f, 0.000000f, \n",
      "0.000000f, 0.000000f, 0.187500f, 0.937500f, 1.000000f, 0.375000f, 0.000000f, 0.000000f, \n",
      "0.000000f, 0.437500f, 0.937500f, 1.000000f, 1.000000f, 0.125000f, 0.000000f, 0.000000f, \n",
      "0.000000f, 0.000000f, 0.062500f, 1.000000f, 1.000000f, 0.187500f, 0.000000f, 0.000000f, \n",
      "0.000000f, 0.000000f, 0.062500f, 1.000000f, 1.000000f, 0.375000f, 0.000000f, 0.000000f, \n",
      "0.000000f, 0.000000f, 0.062500f, 1.000000f, 1.000000f, 0.375000f, 0.000000f, 0.000000f, \n",
      "0.000000f, 0.000000f, 0.000000f, 0.687500f, 1.000000f, 0.625000f, 0.000000f, 0.000000f, \n",
      "};\n",
      "\n",
      "// Digit 2\n",
      "float x_test[64] = {\n",
      "0.000000f, 0.000000f, 0.000000f, 0.250000f, 0.937500f, 0.750000f, 0.000000f, 0.000000f, \n",
      "0.000000f, 0.000000f, 0.187500f, 1.000000f, 0.937500f, 0.875000f, 0.000000f, 0.000000f, \n",
      "0.000000f, 0.000000f, 0.500000f, 0.812500f, 0.500000f, 1.000000f, 0.000000f, 0.000000f, \n",
      "0.000000f, 0.000000f, 0.062500f, 0.375000f, 0.937500f, 0.687500f, 0.000000f, 0.000000f, \n",
      "0.000000f, 0.062500f, 0.500000f, 0.812500f, 0.937500f, 0.062500f, 0.000000f, 0.000000f, \n",
      "0.000000f, 0.562500f, 1.000000f, 1.000000f, 0.312500f, 0.000000f, 0.000000f, 0.000000f, \n",
      "0.000000f, 0.187500f, 0.812500f, 1.000000f, 1.000000f, 0.687500f, 0.312500f, 0.000000f, \n",
      "0.000000f, 0.000000f, 0.000000f, 0.187500f, 0.687500f, 1.000000f, 0.562500f, 0.000000f, \n",
      "};\n",
      "\n",
      "// Digit 3\n",
      "float x_test[64] = {\n",
      "0.000000f, 0.000000f, 0.437500f, 0.937500f, 0.812500f, 0.062500f, 0.000000f, 0.000000f, \n",
      "0.000000f, 0.500000f, 0.812500f, 0.375000f, 0.937500f, 0.250000f, 0.000000f, 0.000000f, \n",
      "0.000000f, 0.125000f, 0.062500f, 0.812500f, 0.812500f, 0.000000f, 0.000000f, 0.000000f, \n",
      "0.000000f, 0.000000f, 0.125000f, 0.937500f, 0.687500f, 0.062500f, 0.000000f, 0.000000f, \n",
      "0.000000f, 0.000000f, 0.000000f, 0.062500f, 0.750000f, 0.750000f, 0.062500f, 0.000000f, \n",
      "0.000000f, 0.000000f, 0.000000f, 0.000000f, 0.062500f, 0.625000f, 0.500000f, 0.000000f, \n",
      "0.000000f, 0.000000f, 0.500000f, 0.250000f, 0.312500f, 0.875000f, 0.562500f, 0.000000f, \n",
      "0.000000f, 0.000000f, 0.437500f, 0.812500f, 0.812500f, 0.562500f, 0.000000f, 0.000000f, \n",
      "};\n",
      "\n",
      "// Digit 4\n",
      "float x_test[64] = {\n",
      "0.000000f, 0.000000f, 0.000000f, 0.062500f, 0.687500f, 0.000000f, 0.000000f, 0.000000f, \n",
      "0.000000f, 0.000000f, 0.000000f, 0.437500f, 0.500000f, 0.000000f, 0.000000f, 0.000000f, \n",
      "0.000000f, 0.000000f, 0.062500f, 0.812500f, 0.375000f, 0.125000f, 0.125000f, 0.000000f, \n",
      "0.000000f, 0.000000f, 0.437500f, 0.937500f, 0.000000f, 0.562500f, 0.500000f, 0.000000f, \n",
      "0.000000f, 0.312500f, 1.000000f, 0.625000f, 0.000000f, 1.000000f, 0.375000f, 0.000000f, \n",
      "0.000000f, 0.250000f, 0.937500f, 1.000000f, 0.812500f, 1.000000f, 0.062500f, 0.000000f, \n",
      "0.000000f, 0.000000f, 0.000000f, 0.187500f, 0.937500f, 0.625000f, 0.000000f, 0.000000f, \n",
      "0.000000f, 0.000000f, 0.000000f, 0.125000f, 1.000000f, 0.250000f, 0.000000f, 0.000000f, \n",
      "};\n",
      "\n",
      "// Digit 5\n",
      "float x_test[64] = {\n",
      "0.000000f, 0.000000f, 0.750000f, 0.625000f, 0.000000f, 0.000000f, 0.000000f, 0.000000f, \n",
      "0.000000f, 0.000000f, 0.875000f, 1.000000f, 1.000000f, 0.875000f, 0.000000f, 0.000000f, \n",
      "0.000000f, 0.000000f, 0.812500f, 1.000000f, 0.937500f, 0.625000f, 0.062500f, 0.000000f, \n",
      "0.000000f, 0.000000f, 0.687500f, 1.000000f, 1.000000f, 0.437500f, 0.000000f, 0.000000f, \n",
      "0.000000f, 0.000000f, 0.000000f, 0.250000f, 0.437500f, 1.000000f, 0.437500f, 0.000000f, \n",
      "0.000000f, 0.000000f, 0.000000f, 0.000000f, 0.250000f, 1.000000f, 0.562500f, 0.000000f, \n",
      "0.000000f, 0.000000f, 0.312500f, 0.250000f, 0.750000f, 1.000000f, 0.250000f, 0.000000f, \n",
      "0.000000f, 0.000000f, 0.562500f, 1.000000f, 1.000000f, 0.625000f, 0.000000f, 0.000000f, \n",
      "};\n",
      "\n",
      "// Digit 6\n",
      "float x_test[64] = {\n",
      "0.000000f, 0.000000f, 0.000000f, 0.750000f, 0.812500f, 0.000000f, 0.000000f, 0.000000f, \n",
      "0.000000f, 0.000000f, 0.312500f, 1.000000f, 0.500000f, 0.000000f, 0.000000f, 0.000000f, \n",
      "0.000000f, 0.000000f, 0.812500f, 1.000000f, 0.187500f, 0.000000f, 0.000000f, 0.000000f, \n",
      "0.000000f, 0.000000f, 0.875000f, 0.812500f, 0.000000f, 0.000000f, 0.000000f, 0.000000f, \n",
      "0.000000f, 0.000000f, 0.937500f, 0.750000f, 0.437500f, 0.125000f, 0.000000f, 0.000000f, \n",
      "0.000000f, 0.000000f, 0.812500f, 1.000000f, 0.812500f, 1.000000f, 0.187500f, 0.000000f, \n",
      "0.000000f, 0.000000f, 0.437500f, 1.000000f, 0.687500f, 0.937500f, 0.500000f, 0.000000f, \n",
      "0.000000f, 0.000000f, 0.062500f, 0.562500f, 0.937500f, 0.687500f, 0.187500f, 0.000000f, \n",
      "};\n",
      "\n",
      "// Digit 7\n",
      "float x_test[64] = {\n",
      "0.000000f, 0.000000f, 0.437500f, 0.500000f, 0.812500f, 1.000000f, 0.937500f, 0.062500f, \n",
      "0.000000f, 0.000000f, 0.437500f, 0.437500f, 0.250000f, 0.687500f, 0.750000f, 0.000000f, \n",
      "0.000000f, 0.000000f, 0.000000f, 0.000000f, 0.500000f, 0.812500f, 0.062500f, 0.000000f, \n",
      "0.000000f, 0.250000f, 0.500000f, 0.500000f, 0.937500f, 0.937500f, 0.375000f, 0.000000f, \n",
      "0.000000f, 0.125000f, 0.687500f, 0.937500f, 0.937500f, 0.250000f, 0.000000f, 0.000000f, \n",
      "0.000000f, 0.000000f, 0.000000f, 1.000000f, 0.312500f, 0.000000f, 0.000000f, 0.000000f, \n",
      "0.000000f, 0.000000f, 0.562500f, 0.937500f, 0.062500f, 0.000000f, 0.000000f, 0.000000f, \n",
      "0.000000f, 0.000000f, 0.812500f, 0.312500f, 0.000000f, 0.000000f, 0.000000f, 0.000000f, \n",
      "};\n",
      "\n",
      "// Digit 8\n",
      "float x_test[64] = {\n",
      "0.000000f, 0.000000f, 0.562500f, 0.875000f, 0.500000f, 0.062500f, 0.000000f, 0.000000f, \n",
      "0.000000f, 0.000000f, 0.750000f, 0.875000f, 0.875000f, 0.750000f, 0.000000f, 0.000000f, \n",
      "0.000000f, 0.000000f, 0.562500f, 0.625000f, 0.000000f, 0.937500f, 0.250000f, 0.000000f, \n",
      "0.000000f, 0.000000f, 0.187500f, 1.000000f, 0.750000f, 0.875000f, 0.125000f, 0.000000f, \n",
      "0.000000f, 0.000000f, 0.250000f, 1.000000f, 1.000000f, 0.125000f, 0.000000f, 0.000000f, \n",
      "0.000000f, 0.187500f, 1.000000f, 0.500000f, 0.625000f, 0.812500f, 0.125000f, 0.000000f, \n",
      "0.000000f, 0.062500f, 0.937500f, 0.062500f, 0.187500f, 1.000000f, 0.500000f, 0.000000f, \n",
      "0.000000f, 0.000000f, 0.687500f, 1.000000f, 0.937500f, 0.687500f, 0.062500f, 0.000000f, \n",
      "};\n",
      "\n",
      "// Digit 9\n",
      "float x_test[64] = {\n",
      "0.000000f, 0.000000f, 0.687500f, 0.750000f, 0.000000f, 0.000000f, 0.000000f, 0.000000f, \n",
      "0.000000f, 0.125000f, 1.000000f, 1.000000f, 1.000000f, 0.812500f, 0.000000f, 0.000000f, \n",
      "0.000000f, 0.187500f, 1.000000f, 0.750000f, 0.625000f, 0.875000f, 0.000000f, 0.000000f, \n",
      "0.000000f, 0.062500f, 1.000000f, 0.062500f, 0.750000f, 0.937500f, 0.000000f, 0.000000f, \n",
      "0.000000f, 0.000000f, 0.812500f, 1.000000f, 0.562500f, 0.937500f, 0.125000f, 0.000000f, \n",
      "0.000000f, 0.000000f, 0.000000f, 0.187500f, 0.000000f, 0.562500f, 0.687500f, 0.000000f, \n",
      "0.000000f, 0.000000f, 0.000000f, 0.000000f, 0.562500f, 0.937500f, 0.250000f, 0.000000f, \n",
      "0.000000f, 0.000000f, 0.562500f, 0.750000f, 0.812500f, 0.187500f, 0.000000f, 0.000000f, \n",
      "};\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# TO GET THE ORIGINAL INPUTS, RECALL THE FUNCTIONS FROM ABOVE\n",
    "\n",
    "# Load and preprocess the digits dataset\n",
    "def get_data():\n",
    "    np.random.seed(1337)\n",
    "    x_values, y_values = load_digits(return_X_y=True)\n",
    "    x_values /= x_values.max()\n",
    "    # reshape to (8, 8, 1)\n",
    "    x_values = x_values.reshape((len(x_values), 8, 8, 1))\n",
    "    return x_values, y_values\n",
    "\n",
    "# Get the data\n",
    "x_values, y_values = get_data()\n",
    "\n",
    "# Function to print the input data in Arduino-friendly format\n",
    "def print_arduino_format(data, label):\n",
    "    flattened_data = data.flatten()\n",
    "    print(f\"// Digit {label}\")\n",
    "    print(\"float x_test[64] = {\")\n",
    "    for i in range(len(flattened_data)):\n",
    "        if i % 8 == 0 and i != 0:  # Print 8 values per line for readability\n",
    "            print()\n",
    "        print(f\"{flattened_data[i]:.6f}f,\", end=\" \")\n",
    "    print(\"\\n};\\n\")\n",
    "\n",
    "# Create and print one sample input for each digit (0-9)\n",
    "for digit in range(10):\n",
    "    # Find the first occurrence of the digit in the dataset\n",
    "    index = np.where(y_values == digit)[0][0]\n",
    "    sample_input = x_values[index]\n",
    "    print_arduino_format(sample_input, digit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "StqHPdCit5f7",
    "outputId": "b0411df6-7833-4dff-f98c-207c40a6d12c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Quantized model accuracy: 0.9498607242339833\n"
     ]
    }
   ],
   "source": [
    "interpreter = tf.lite.Interpreter(model_path='cnn_mnist_model_quantized.tflite')\n",
    "interpreter.allocate_tensors()\n",
    "input_index = interpreter.get_input_details()[0]['index']\n",
    "output_index = interpreter.get_output_details()[0]['index']\n",
    "\n",
    "correct_predictions = 0\n",
    "for i in range(len(x_test)):\n",
    "    input_data = np.expand_dims(x_test[i], axis=0).astype(np.float32)  # Ensure input data is float32\n",
    "    interpreter.set_tensor(input_index, input_data)\n",
    "    interpreter.invoke()\n",
    "    prediction = interpreter.get_tensor(output_index).argmax()\n",
    "    if prediction == y_test[i]:\n",
    "        correct_predictions += 1\n",
    "\n",
    "accuracy = correct_predictions / len(x_test)\n",
    "print('Quantized model accuracy:', accuracy)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
